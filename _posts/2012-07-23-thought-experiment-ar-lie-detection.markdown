---
layout: post
template: post
date: 2012-07-23
title: "Thought Experiment: AR Lie Detection"
permalink: /post/27820511355/thought-experiment-ar-lie-detection
description: "Thought Experiment: AR Lie Detection"
---
<p>I've previously <a href="http://blog.randylubin.com/post/18079173691/eagerly-anticipating-google-glasses-social">speculated</a> on the killer app for Augmented Reality goggles and I've continued to think about functionality. In this post, I'll flesh out a new feature: lie detection.</p>&#13;
<p>When humans lie, we make small, involuntary <a href="http://en.wikipedia.org/wiki/Microexpression">microexpressions</a>. AR Glasses could use computer vision to identify microexpressions that signal the deception. Upon detection of the lie, the glasses could alert the wearer (and indicated the degree of confidence).</p>&#13;
<p>This <a href="http://spie.org/x84912.xml">study</a> explains a machine learning algorithm that was able to detect microexpressions and classify them as positive or negative with over 70% accuracy; human accuracy is below 50%. As camera technology and machine learning improve, I expect to see this accuracy increase rapidly. It's a short leap to picture the tech integrated into AR Glasses, like the increasingly hyped Project Glass, by Google.</p>&#13;
<p>Lie detection glasses would have obvious use to law enforcement officers, but the tech would likely trickle down to the public as well. This will clearly run up against cultural norms; under what circumstances will it be okay to use this tech? Parents may try to use it on their children, bosses may try it on their employees. Ultimately it may lead to a more open, transparent society as lying becomes more difficult / obvious, but it would be an awkward transition.</p>&#13;
<p>One alternate use of the same tech is to boost emotional intelligence. Micoexpressions signal a whole spectrum of emotions that may otherwise go unrecognized. This type of use could facilitate much higher fidelity communication as both parties have a better sense of what the other is feeling; people could better see the impact of their dialogue as they are talking, and correct misunderstandings much more rapidly.</p>&#13;
<p>How else could we use this technology?</p>&#13;
<p>--</p>&#13;
<p><a href="https://twitter.com/nickpinkston">Nick Pinkston</a> had this great feedback:</p>&#13;
<blockquote>&#13;
<p>Microexpressions are pretty cool, but don't forget voice stress algorithms either! I think the DSP involved is waaaaay easier than microexpression video analysis from a compute standpoint - meaning that that battery would be better and/or the speed would be increased.</p>&#13;
</blockquote>&#13;
<p>Great idea, and makes a lot of sense.</p> 